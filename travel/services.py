import random
import requests
import json
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from django.conf import settings
from openai import OpenAI, OpenAIError
from langchain_openai import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

client = OpenAI(api_key=settings.OPENAI_API_KEY)

# âœ… OpenAI API ë° ë„¤ì´ë²„ API ì„¤ì •
NAVER_CLIENT_ID = settings.NAVER_CLIENT_ID
NAVER_CLIENT_SECRET = settings.NAVER_CLIENT_SECRET

# âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (BERT ê¸°ë°˜ SentenceTransformer)
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
embedding_dim = embedding_model.get_sentence_embedding_dimension()

# âœ… FAISS ì¸ë±ìŠ¤ ìƒì„±
faiss_index = faiss.IndexFlatL2(embedding_dim)
document_texts = []  # ë¬¸ì„œ ì›ë³¸ ì €ì¥


# ------------------------------------------------------------------------------
# âœ… 1. ë„¤ì´ë²„ API ì—¬í–‰ì§€ ì¶”ì²œ (get_travel_recommendations)
# ------------------------------------------------------------------------------
def get_travel_recommendations(keyword, display_count=5):
    """
    ë„¤ì´ë²„ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬í–‰ì§€ ì¶”ì²œ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    """
    url = "https://openapi.naver.com/v1/search/local.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    params = {"query": keyword, "display": display_count}
    response = requests.get(url, headers=headers, params=params)

    if response.status_code == 200:
        try:
            data = response.json()
            travel_spots = [item["title"].replace("<b>", "").replace("</b>", "") for item in data["items"]]
            print(data)
            return "\n".join(travel_spots) if travel_spots else "ë„¤ì´ë²„ APIì—ì„œ ì—¬í–‰ì§€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except json.JSONDecodeError:
            return "API ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    else:
        return f"ë„¤ì´ë²„ API ì˜¤ë¥˜ ë°œìƒ (ìƒíƒœ ì½”ë“œ: {response.status_code})"


# ------------------------------------------------------------------------------
# âœ… 2. ë„¤ì´ë²„ API í¬ë¡¤ë§ ë°ì´í„° ìˆ˜ì§‘ (fetch_data_from_naver, crawl_naver_api)
# ------------------------------------------------------------------------------
def fetch_data_from_naver(query="ì—¬í–‰", display_count=50):
    from .models import CrawledData
    """
    ë„¤ì´ë²„ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì—¬í–‰ ê´€ë ¨ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    """
    url = "https://openapi.naver.com/v1/search/local.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    params = {"query": query, "display": display_count}

    response = requests.get(url, headers=headers, params=params)
    if response.status_code == 200:
        data = response.json()
        for item in data['items']:  # API ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ì²˜ë¦¬
            title = item['title'].replace("<b>", "").replace("</b>", "").replace("&amp;", "")
            content = item['description'].replace("<b>", "").replace("</b>", "").replace("&amp;", "")
            url = item['link']

            # ë„¤ì´ë²„ í¬ë¡¤ë§ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            crawled_data = CrawledData.objects.create(
                title=title,
                content=content,
                url=url,
                embedding=None  # ì„ë² ë”©ì€ ë‚˜ì¤‘ì— ì²˜ë¦¬
            )


def crawl_naver_api(query, display_count=50):
    """
    ë„¤ì´ë²„ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬í–‰ ê´€ë ¨ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜.
    """
    url = "https://openapi.naver.com/v1/search/local.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    params = {"query": query, "display": display_count}
    response = requests.get(url, headers=headers, params=params)

    if response.status_code == 200:
        try:
            data = response.json()
            docs = []
            for item in data.get("items", []):
                text = item.get("title", "") + " " + item.get("description", "")
                text = text.replace("<b>", "").replace("</b>", "")
                docs.append(text.strip())
            return docs
        except json.JSONDecodeError:
            return []
    else:
        return []


# ------------------------------------------------------------------------------
# âœ… 3. FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ë° ê²€ìƒ‰
# ------------------------------------------------------------------------------
def build_faiss_index(docs):
    """
    í¬ë¡¤ë§í•œ ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ê³ , FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    """
    global faiss_index, document_texts
    if docs:
        embeddings = embedding_model.encode(docs, convert_to_numpy=True)
        faiss_index.reset()
        faiss_index.add(embeddings)
        document_texts = docs
    return faiss_index


def search_faiss_index(query, top_k=3):
    """
    FAISS ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ ì¿¼ë¦¬ì— ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰.
    """
    query_embedding = embedding_model.encode([query], convert_to_numpy=True)
    distances, indices = faiss_index.search(query_embedding, top_k)
    results = [document_texts[idx] for idx in indices[0] if idx < len(document_texts)]
    return results


# ------------------------------------------------------------------------------
# âœ… 4. RAG ê¸°ë°˜ ì—¬í–‰ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
# ------------------------------------------------------------------------------
def retrieve_travel_context(query, display_count=3):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬í–‰ ì¼ì • ê´€ë ¨ ì°¸ê³  ìë£Œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    """
    prompt = (
        f"'{query}'ì— ëŒ€í•œ ì—¬í–‰ ì¼ì •ì„ ê³„íší•˜ê¸° ìœ„í•œ ê°„ê²°í•œ ì—¬í–‰ ì»¨í…ìŠ¤íŠ¸ì™€ ê°€ì´ë“œë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”. "
        "ë‹µë³€ì€ ì§§ì€ ë¬¸ë‹¨ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
    )
    
    docs = crawl_naver_api(query=query, display_count=display_count)
    
    if docs:
        build_faiss_index(docs)
        top_docs = search_faiss_index(query, top_k=5)
        print(top_docs)
        return top_docs  # ğŸ”¹ ê°œí–‰ìœ¼ë¡œ ë¬¸ì¥ êµ¬ë¶„
    else:
        return "ê´€ë ¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."


# ------------------------------------------------------------------------------
# âœ… 5. LangChain LLMì„ ì´ìš©í•œ ì±—ë´‡ ì‘ë‹µ ìƒì„±
# ------------------------------------------------------------------------------
def generate_response(user_data, user_input):
    """
    LangChainì˜ LLMChainì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    """
    retrieved_context = retrieve_travel_context(user_input)

    prompt_template = PromptTemplate(
        input_variables=["retrieved_context", "user_input", "user_data"],
        template="ğŸ“Œ ì°¸ê³  ìë£Œ:\n{retrieved_context}\n\n"
                 "â“ ì‚¬ìš©ì ì§ˆë¬¸:\n{user_input}\n\n"
                 "âœï¸ ë‹µë³€:"
    )

    chat_model = OpenAI(model="gpt-4", temperature=0)
    
    chain = LLMChain(llm=chat_model, prompt=prompt_template)

    response = chain.invoke({
        "retrieved_context": retrieved_context,
        "user_input": user_input,
        "user_data": user_data,
    })
    print(response)

    return response.replace("\n", " ")  # ğŸ”¹ ê°œí–‰ ì—†ì´ ë¬¸ì¥ ìœ ì§€


# ------------------------------------------------------------------------------
# âœ… 6. ChatbotService (LangChain + RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±)
# ------------------------------------------------------------------------------
class ChatbotService:
    @staticmethod
    def get_chatgpt_response(user_input, user_data):
        try:
            return generate_response(user_data, user_input)
        except OpenAIError as oe:
            return {"error": f"OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {str(oe)}"}
        except Exception as e:
            return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
